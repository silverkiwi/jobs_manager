import logging
from dataclasses import dataclass
from decimal import Decimal
from enum import Enum
from typing import Any, Dict, List, Optional

import pandas as pd

from .draft import DraftLine

logger = logging.getLogger(__name__)


class ErrorSeverity(Enum):
    """Severity levels for validation errors."""

    WARNING = "warning"  # Non-blocking, proceed with import
    ERROR = "error"  # Blocking, reject import
    CRITICAL = "critical"  # Critical format issues, cannot parse


class ErrorType(Enum):
    """Types of validation errors."""

    # Format errors (critical)
    MISSING_REQUIRED_COLUMNS = "missing_required_columns"
    INVALID_SHEET_STRUCTURE = "invalid_sheet_structure"

    # Data conflicts (errors - blocking)
    LABOUR_MATERIAL_CONFLICT = "labour_material_conflict"
    INVALID_ITEM_FORMAT = "invalid_item_format"
    PRICING_MISMATCH = "pricing_mismatch"

    # Validation warnings (non-blocking)
    MARKUP_MISMATCH = "markup_mismatch"
    CHARGE_RATE_MISMATCH = "charge_rate_mismatch"
    TOTALS_MISMATCH = "totals_mismatch"


@dataclass
class ValidationError:
    """Individual validation error with context."""

    error_type: ErrorType
    severity: ErrorSeverity
    message: str
    row_number: Optional[int] = None
    column: Optional[str] = None
    expected_value: Optional[Any] = None
    actual_value: Optional[Any] = None
    suggestion: Optional[str] = None

    def to_dict(self) -> Dict[str, Any]:
        """Convert ValidationError to dictionary for JSON serialization."""
        return {
            "error_type": self.error_type.value if self.error_type else None,
            "severity": self.severity.value if self.severity else None,
            "message": self.message,
            "row_number": self.row_number,
            "column": self.column,
            "expected_value": self.expected_value,
            "actual_value": self.actual_value,
            "suggestion": self.suggestion,
        }


@dataclass
class ValidationReport:
    """Complete validation report for a spreadsheet."""

    is_valid: bool
    can_proceed: bool  # True if only warnings, False if errors/critical
    errors: List[ValidationError]
    warnings: List[ValidationError]
    critical_issues: List[ValidationError]
    summary: Dict[str, Any]

    def has_blocking_issues(self) -> bool:
        """Check if there are any blocking issues (errors or critical)."""
        return len(self.errors) > 0 or len(self.critical_issues) > 0

    def get_error_summary(self) -> str:
        """Get a human-readable summary of all issues."""
        if not self.errors and not self.warnings and not self.critical_issues:
            return "‚úÖ No validation issues found"

        summary_parts = []
        if self.critical_issues:
            summary_parts.append(f"üö® {len(self.critical_issues)} critical issue(s)")
        if self.errors:
            summary_parts.append(f"‚ùå {len(self.errors)} error(s)")
        if self.warnings:
            summary_parts.append(f"‚ö†Ô∏è {len(self.warnings)} warning(s)")

        return " | ".join(summary_parts)

    def to_dict(self) -> Dict[str, Any]:
        """Convert ValidationReport to dictionary for JSON serialization."""
        # Combine all issues into a single list with consistent format
        all_issues = []

        # Add critical issues
        for issue in self.critical_issues:
            issue_dict = issue.to_dict()
            issue_dict["severity"] = "error"  # Treat critical as error for frontend
            all_issues.append(issue_dict)

        # Add errors
        for issue in self.errors:
            all_issues.append(issue.to_dict())

        # Add warnings
        for issue in self.warnings:
            all_issues.append(issue.to_dict())

        return {
            "is_valid": self.is_valid,
            "can_proceed": self.can_proceed,
            "issues": all_issues,
            "errors": [issue.message for issue in self.errors],
            "warnings": [issue.message for issue in self.warnings],
            "summary": self.summary,
        }


def _d(val):
    """Safely coerce values to Decimal with 2 decimal places precision."""
    try:
        # Handle pandas NaN, None, empty strings
        if pd.isna(val) or val is None or val == "":
            return Decimal("0")

        # Convert to string and clean common issues
        str_val = str(val).strip()
        if str_val.lower() in ["nan", "none", "", "#n/a"]:
            return Decimal("0")

        # Remove any currency symbols or commas
        str_val = str_val.replace("$", "").replace(",", "").replace(" ", "")

        return Decimal(str_val).quantize(Decimal("0.01"))
    except (ValueError, TypeError, Exception):
        return Decimal("0")


PRIMARY_SHEET = "Primary Details"

# Support both workbook layouts
LABOUR_COLS = ["Labour /laser (inhouse)", "assembly"]  # older and newer files
MATERIAL_TOTAL_COL = "total cost"  # column N (but may have trailing space)
MATERIAL_ITEM_COL = "item cost"  # column O
QUANTITY_COL = "quantity"  # column B

# Default values if CompanyDefaults not available
DEFAULT_WAGE_RATE = Decimal("32.00")
DEFAULT_CHARGE_OUT_RATE = Decimal("110.00")
DEFAULT_MATERIALS_MARKUP = Decimal("0.20")  # 20%

# Columns to ignore for DraftLine creation
IGNORE_COLS = [
    "total cost",
    "item cost",
    "Labour hours cost",
    "Cost before MU",
    "Total cost + MU",
]


def detect_labour_column(df):
    """Detect which labour column is present in this workbook."""
    for col in LABOUR_COLS:
        if col in df.columns:
            return col
    # If no labour column found, we'll just process materials
    return None


def detect_material_columns(df):
    """Detect material cost columns, handling trailing spaces."""
    total_col = None
    item_col = None

    # Look for total cost column (may have trailing space)
    for col in df.columns:
        if col.strip().lower() == "total cost":
            total_col = col
            break

    # Look for item cost column
    for col in df.columns:
        if col.strip().lower() == "item cost":
            item_col = col
            break

    return total_col, item_col


def parse_xlsx(
    path: str, company=None, skip_validation=False
) -> tuple[list[DraftLine], list[str]]:
    """
    Parse the Quoting Spreadsheet and convert Primary Details sheet
    into a list of DraftLine objects with validation.

    Args:
        path: Path to the Excel file
        company: Company object with wage_rate and charge_out_rate (optional)
        skip_validation: Skip pre-import validation (default: False)

    Returns:
        tuple: (draft_lines, validation_report)
    """
    try:
        # Perform pre-import validation
        if not skip_validation:
            validation_report = validate_spreadsheet_format(path)

            # Reject if critical issues or blocking errors
            if validation_report.has_blocking_issues():
                error_summary = []

                # Add critical issues
                for issue in validation_report.critical_issues:
                    error_summary.append(f"CRITICAL: {issue.message}")

                # Add blocking errors
                for issue in validation_report.errors:
                    error_summary.append(f"ERROR: {issue.message}")
                    if issue.row_number:
                        error_summary[-1] += f" (Row {issue.row_number})"
                    if issue.suggestion:
                        error_summary[-1] += f" - {issue.suggestion}"

                # Return empty results with detailed error report
                return [], error_summary
        # Read the Primary Details sheet
        logger.info(f"üîç Reading Primary Details sheet from: {path}")
        df = pd.read_excel(path, sheet_name=PRIMARY_SHEET)
        logger.info(f"üìä Loaded DataFrame with shape: {df.shape}")
        logger.info(f"üìã DataFrame columns: {list(df.columns)}")

        # Log sample of raw data
        logger.info(f"üìù Sample raw data (first 3 rows):")
        for i in range(min(3, len(df))):
            row_data = df.iloc[i].to_dict()
            logger.info(f"    Row {i}: {row_data}")

        # Read pricing details for validation
        pricing_df = None
        try:
            pricing_df = pd.read_excel(path, sheet_name="pricing details - inhouse")
            logger.info(f"üìä Also loaded pricing details sheet")
        except Exception:
            logger.info(f"üìä No pricing details sheet found (optional)")
            pass  # Optional sheet for validation

        # Detect columns
        labour_col = detect_labour_column(df)
        material_total_col, material_item_col = detect_material_columns(
            df
        )  # Get company rates from CompanyDefaults if available
        if company:
            wage_rate = getattr(company, "wage_rate", DEFAULT_WAGE_RATE)
            charge_out_rate = getattr(
                company, "charge_out_rate", DEFAULT_CHARGE_OUT_RATE
            )
            materials_markup = getattr(
                company, "materials_markup", DEFAULT_MATERIALS_MARKUP
            )
        else:
            # Try to get from CompanyDefaults model
            try:
                from apps.workflow.models import CompanyDefaults

                defaults = CompanyDefaults.objects.first()
                if defaults:
                    wage_rate = defaults.wage_rate
                    charge_out_rate = defaults.charge_out_rate
                    materials_markup = defaults.materials_markup
                else:
                    wage_rate = DEFAULT_WAGE_RATE
                    charge_out_rate = DEFAULT_CHARGE_OUT_RATE
                    materials_markup = DEFAULT_MATERIALS_MARKUP
            except (ImportError, Exception):
                wage_rate = DEFAULT_WAGE_RATE
                charge_out_rate = DEFAULT_CHARGE_OUT_RATE
                materials_markup = DEFAULT_MATERIALS_MARKUP

        draft_lines = []
        total_minutes = Decimal("0")
        valid_items_count = 0
        skipped_items_count = 0

        logger.info(f"üîß Starting to process rows (max 45 rows)...")
        # Process rows - only those with valid item numbers in column A or valid quantity
        auto_item_number = 1  # Counter for auto-assigned item numbers

        for idx in range(0, min(45, len(df))):
            row = df.iloc[idx]
            excel_row = idx + 1  # Convert to Excel row number

            logger.debug(f"Processing row {excel_row}: {row.to_dict()}")

            # Check 1: Quantity first (must have value and not be zero)
            quantity = _d(row.get(QUANTITY_COL, 1))
            if quantity <= 0:
                logger.debug(
                    f"    ‚è≠Ô∏è Row {excel_row}: Invalid quantity {quantity}, skipping"
                )
                skipped_items_count += 1
                continue

            # Check 2: Item number - auto-assign if missing or invalid
            item_number = str(row.get("item", "")).strip()
            if not item_number or item_number.lower() in ["nan", "none", ""]:
                # Auto-assign sequential item number
                item_number = str(auto_item_number)
                logger.info(
                    f"    üîÑ Row {excel_row}: No item number, auto-assigned: {item_number}"
                )
                auto_item_number += 1
            else:
                try:
                    float(item_number)  # Accept floats like 1.0, 2.0
                    auto_item_number = max(
                        auto_item_number, int(float(item_number)) + 1
                    )  # Update counter
                except (ValueError, TypeError):
                    # Invalid item number, auto-assign
                    item_number = str(auto_item_number)
                    logger.info(
                        f"    üîÑ Row {excel_row}: Invalid item number, auto-assigned: {item_number}"
                    )
                    auto_item_number += 1

            # Check 3: Description (if empty, use item number as fallback)
            description = str(row.get("Description", "")).strip()
            if not description or description.lower() in ["nan", "none", ""]:
                description = (
                    f"Item {item_number}"  # Use item number as description if blank
                )

            logger.info(
                f"    ‚úÖ Row {excel_row}: Valid item - {item_number}, qty: {quantity}, desc: '{description}'"
            )
            valid_items_count += 1
            # Get values from key columns only (A, B, C, D, N, O)
            minutes = _d(row.get(labour_col, 0)) if labour_col else Decimal("0")
            material_total_cost = (
                _d(row.get(material_total_col, 0))
                if material_total_col
                else Decimal("0")
            )
            material_item_cost = (
                _d(row.get(material_item_col, 0)) if material_item_col else Decimal("0")
            )  # Business logic: 1 DraftLine per item
            # IF labour exists ‚Üí kind='time'
            # ELSE IF item cost exists ‚Üí kind='material'
            # VALIDATION: Cannot have both labour AND material
            has_labour = minutes > 0
            has_material = material_total_cost > 0 or material_item_cost > 0

            # Validation check: item cannot have both labour and material
            if has_labour and has_material:
                print(
                    f"‚ö†Ô∏è  WARNING: Row {excel_row} has both labour ({minutes} min) and material costs (${material_total_cost}/${material_item_cost}). Using labour only."
                )

            if has_labour:
                # Create time entry (labour minutes ‚Üí hours)
                hours = (minutes / Decimal("60")).quantize(Decimal("0.01"))
                total_minutes += minutes

                draft_lines.append(
                    DraftLine(
                        kind="time",
                        desc=f"{description} - Labour",
                        quantity=hours,
                        unit_cost=wage_rate,
                        unit_rev=charge_out_rate,
                        source_row=excel_row,
                        source_sheet=PRIMARY_SHEET,
                    )
                )

            elif has_material:
                # Create material entry
                # unit_cost comes from column O ("item cost")
                # unit_rev = unit_cost * (1 + materials_markup)
                unit_cost = material_item_cost
                unit_rev = unit_cost * (1 + materials_markup)

                draft_lines.append(
                    DraftLine(
                        kind="material",
                        desc=f"{description} - Materials",
                        quantity=quantity,
                        unit_cost=unit_cost,
                        unit_rev=unit_rev,
                        source_row=excel_row,
                        source_sheet=PRIMARY_SHEET,
                    )
                )

            # If neither labour nor material, skip this item        # Validation - collect totals from summary rows
        validation_report = validate_totals(
            df, draft_lines, total_minutes, labour_col, materials_markup, pricing_df
        )

        logger.info(f"‚úÖ Parsing completed!")
        logger.info(f"üìä Final statistics:")
        logger.info(f"    Valid items processed: {valid_items_count}")
        logger.info(f"    Items skipped: {skipped_items_count}")
        logger.info(f"    Draft lines created: {len(draft_lines)}")
        logger.info(f"    Total minutes: {total_minutes}")

        # Log sample of created draft lines
        logger.info(f"üìù Sample draft lines created:")
        for i, line in enumerate(draft_lines[:3]):
            logger.info(f"    Line {i}: {line}")

        return draft_lines, validation_report

    except FileNotFoundError:
        raise FileNotFoundError(f"Excel file not found: {path}")
    except Exception as e:
        raise Exception(f"Error parsing Excel file: {str(e)}")


def find_validation_cells(df, labour_col):
    """
    Find validation cells dynamically based on content, not fixed positions.

    Returns:
        dict: Contains validation values found in the spreadsheet
    """
    validation_data = {
        "total_minutes": Decimal("0"),
        "labour_revenue": Decimal("0"),
        "material_cost_before_mu": Decimal("0"),
        "material_cost_with_mu": Decimal("0"),
        "final_cost": Decimal("0"),
    }

    try:
        # Search through the dataframe for specific text patterns
        for idx in range(len(df)):
            row = df.iloc[idx]

            # Check Description column for key markers
            description = str(row.get("Description", "")).strip().lower()

            if "labour hours cost" in description:
                # Labour revenue is to the right (in labour column)
                validation_data["labour_revenue"] = _d(row.get(labour_col, 0))

            elif "cost before mu" in description:
                # Material cost before markup is to the right (in labour column)
                validation_data["material_cost_before_mu"] = _d(row.get(labour_col, 0))

            elif "total cost + mu" in description or (
                "total cost" in description and "mu" in description
            ):
                # Material cost with markup is to the right (in labour column)
                validation_data["material_cost_with_mu"] = _d(row.get(labour_col, 0))

            elif "final cost" in description:
                # Final cost is to the right (in labour column)
                validation_data["final_cost"] = _d(row.get(labour_col, 0))
        # Find total minutes: last non-zero value in labour column before "Labour hours cost" line
        if labour_col:
            labour_hours_cost_idx = None

            # First, find the "Labour hours cost" line
            for idx in range(len(df)):
                row = df.iloc[idx]
                description = str(row.get("Description", "")).strip().lower()
                if "labour hours cost" in description:
                    labour_hours_cost_idx = idx
                    break

            # Then search backwards from that line to find the last minutes value
            if labour_hours_cost_idx is not None:
                for idx in range(labour_hours_cost_idx - 1, -1, -1):
                    row = df.iloc[idx]
                    minutes_val = _d(row.get(labour_col, 0))
                    if minutes_val > 0:
                        validation_data["total_minutes"] = minutes_val
                        break

    except Exception as e:
        print(f"Warning: Could not find all validation cells: {e}")

    return validation_data


def validate_totals(
    df,
    lines,
    total_minutes,
    labour_col,
    materials_markup=DEFAULT_MATERIALS_MARKUP,
    pricing_df=None,
):
    """
    Validate our computed totals against spreadsheet summary rows using dynamic content-based search.

    Returns:
        list[str]: Validation issues found
    """
    issues = []

    try:
        # Validate pricing details if available
        if pricing_df is not None and len(pricing_df) > 1:
            # Get labour cost and margin from pricing details (row 1)
            spreadsheet_labour_cost = _d(pricing_df.iloc[1].get("labour cost", 0))
            spreadsheet_margin = _d(pricing_df.iloc[1].get("margin", 1.2))

            # Get our company defaults for comparison
            from apps.workflow.models import CompanyDefaults

            try:
                defaults = CompanyDefaults.objects.first()
                if defaults:
                    our_charge_out_rate = defaults.charge_out_rate
                    our_materials_markup = defaults.materials_markup

                    # Validate labour cost (should match charge_out_rate)
                    if abs(spreadsheet_labour_cost - our_charge_out_rate) > Decimal(
                        "0.01"
                    ):
                        issues.append(
                            f"Labour cost mismatch: spreadsheet ${spreadsheet_labour_cost}, system ${our_charge_out_rate}"
                        )

                    # Validate margin (1.2 = 20% markup)
                    spreadsheet_markup = (
                        spreadsheet_margin - 1
                        if spreadsheet_margin > 1
                        else Decimal("0")
                    )
                    if abs(spreadsheet_markup - our_materials_markup) > Decimal("0.01"):
                        issues.append(
                            f"Material markup mismatch: spreadsheet {spreadsheet_markup:.1%}, system {our_materials_markup:.1%}"
                        )
            except Exception:
                pass  # Skip validation if can't access CompanyDefaults

        # Find validation cells dynamically based on content
        validation_data = find_validation_cells(df, labour_col)
        # Compute our totals
        our_minutes = sum(line.quantity * 60 for line in lines if line.kind == "time")
        our_labour_rev = sum(
            line.quantity * line.unit_rev for line in lines if line.kind == "time"
        )
        our_material_cost = sum(
            line.quantity * line.unit_cost for line in lines if line.kind == "material"
        )
        our_material_cost_mu = our_material_cost * (1 + materials_markup)
        our_final_cost = our_labour_rev + our_material_cost_mu
        # Check for mismatches using dynamic validation data
        if abs(our_minutes - validation_data["total_minutes"]) > Decimal("0.1"):
            issues.append(
                f"Minutes mismatch: computed {our_minutes}, spreadsheet {validation_data['total_minutes']}"
            )

        if abs(our_labour_rev - validation_data["labour_revenue"]) > Decimal("1.00"):
            issues.append(
                f"Labour revenue mismatch: computed ${our_labour_rev}, spreadsheet ${validation_data['labour_revenue']}"
            )

        if abs(
            our_material_cost - validation_data["material_cost_before_mu"]
        ) > Decimal("1.00"):
            issues.append(
                f"Material cost mismatch: computed ${our_material_cost}, spreadsheet ${validation_data['material_cost_before_mu']}"
            )

        if abs(
            our_material_cost_mu - validation_data["material_cost_with_mu"]
        ) > Decimal("1.00"):
            # Check if markup percentage is different
            if validation_data["material_cost_before_mu"] > 0:  # avoid division by zero
                spreadsheet_markup = (
                    validation_data["material_cost_with_mu"]
                    - validation_data["material_cost_before_mu"]
                ) / validation_data["material_cost_before_mu"]
                markup_diff = abs(spreadsheet_markup - materials_markup)
                if markup_diff > Decimal("0.01"):  # 1% tolerance
                    issues.append(
                        f"Spreadsheet uses {spreadsheet_markup:.1%} markup, system uses {materials_markup:.1%}. Adjust markup or accept?"
                    )
                else:
                    issues.append(
                        f"Material + MU mismatch: computed ${our_material_cost_mu}, spreadsheet ${validation_data['material_cost_with_mu']}"
                    )

        if abs(our_final_cost - validation_data["final_cost"]) > Decimal("1.00"):
            issues.append(
                f"Final cost mismatch: computed ${our_final_cost}, spreadsheet ${validation_data['final_cost']}"
            )

    except (IndexError, KeyError) as e:
        issues.append(f"Could not read validation cells: {e}")

    return issues

    return issues


# Backward compatibility wrapper
def parse_xlsx_old(path: str) -> list[DraftLine]:
    """Backward compatibility wrapper - returns only draft_lines."""
    draft_lines, _ = parse_xlsx(path)
    return draft_lines


def parse_xlsx_with_summary(path: str) -> dict:
    """
    Parse the Excel file and return both draft lines and summary statistics.

    Args:
        path: Path to the Excel file

    Returns:
        Dictionary containing 'draft_lines', 'summary', and 'validation_report'
    """
    draft_lines, validation_report = parse_xlsx(path)

    summary = {
        "total_lines": len(draft_lines),
        "time_lines": len([line for line in draft_lines if line.kind == "time"]),
        "material_lines": len(
            [line for line in draft_lines if line.kind == "material"]
        ),
        "adjust_lines": len([line for line in draft_lines if line.kind == "adjust"]),
        "total_cost": sum(line.total_cost for line in draft_lines),
        "total_revenue": sum(line.total_rev for line in draft_lines),
    }

    return {
        "draft_lines": draft_lines,
        "summary": summary,
        "validation_report": validation_report,
    }


def parse_xlsx_with_validation(path: str, company=None) -> dict:
    """
    Parse Excel file with comprehensive validation and error reporting.

    Args:
        path: Path to the Excel file
        company: Company object with wage_rate and charge_out_rate (optional)

    Returns:
        Dictionary containing:
        - 'success': bool - Whether parsing was successful
        - 'can_proceed': bool - Whether import can proceed (no blocking errors)
        - 'draft_lines': list - Parsed DraftLine objects (empty if failed)
        - 'validation_report': ValidationReport - Complete validation results
        - 'summary': dict - Summary statistics
        - 'error_report': list - Human-readable error messages
    """
    try:
        # Always perform validation first
        validation_report = validate_spreadsheet_format(path)

        # Prepare result structure
        result = {
            "success": False,
            "can_proceed": validation_report.can_proceed,
            "draft_lines": [],
            "validation_report": validation_report,
            "summary": validation_report.summary,
            "error_report": [],
        }

        # Generate human-readable error report
        error_report = []

        # Add critical issues
        if validation_report.critical_issues:
            error_report.append("üö® CRITICAL ISSUES (Cannot proceed):")
            for issue in validation_report.critical_issues:
                error_report.append(f"  ‚Ä¢ {issue.message}")
                if issue.suggestion:
                    error_report.append(f"    üí° {issue.suggestion}")

        # Add blocking errors
        if validation_report.errors:
            error_report.append("‚ùå BLOCKING ERRORS (Must fix before import):")
            for issue in validation_report.errors:
                msg = f"  ‚Ä¢ {issue.message}"
                if issue.row_number:
                    msg += f" (Row {issue.row_number})"
                error_report.append(msg)
                if issue.suggestion:
                    error_report.append(f"    üí° {issue.suggestion}")

        # Add warnings
        if validation_report.warnings:
            error_report.append("‚ö†Ô∏è WARNINGS (Non-blocking, import can proceed):")
            for issue in validation_report.warnings:
                msg = f"  ‚Ä¢ {issue.message}"
                if issue.expected_value and issue.actual_value:
                    msg += f" (Expected: {issue.expected_value}, Got: {issue.actual_value})"
                error_report.append(msg)
                if issue.suggestion:
                    error_report.append(f"    üí° {issue.suggestion}")

        result["error_report"] = error_report

        # If there are blocking issues, don't attempt parsing
        if validation_report.has_blocking_issues():
            result["summary"]["parse_attempted"] = False
            result["summary"]["rejection_reason"] = "Blocking validation errors found"
            return result

        # Attempt parsing (skip validation since we already did it)
        draft_lines, legacy_validation_issues = parse_xlsx(
            path, company, skip_validation=True
        )

        # Update result with successful parsing
        result["success"] = True
        result["draft_lines"] = draft_lines
        result["summary"].update(
            {
                "parse_attempted": True,
                "total_lines": len(draft_lines),
                "time_lines": len(
                    [line for line in draft_lines if line.kind == "time"]
                ),
                "material_lines": len(
                    [line for line in draft_lines if line.kind == "material"]
                ),
                "adjust_lines": len(
                    [line for line in draft_lines if line.kind == "adjust"]
                ),
                "total_cost": sum(line.total_cost for line in draft_lines),
                "total_revenue": sum(line.total_rev for line in draft_lines),
            }
        )

        # Add any legacy validation issues as warnings
        if legacy_validation_issues:
            if (
                not error_report
                or error_report[-1] != "‚ö†Ô∏è WARNINGS (Non-blocking, import can proceed):"
            ):
                error_report.append("‚ö†Ô∏è ADDITIONAL VALIDATION NOTES:")
            for issue in legacy_validation_issues:
                error_report.append(f"  ‚Ä¢ {issue}")
            result["error_report"] = error_report

        return result

    except Exception as e:
        # Unexpected error during validation or parsing
        return {
            "success": False,
            "can_proceed": False,
            "draft_lines": [],
            "validation_report": ValidationReport(
                is_valid=False,
                can_proceed=False,
                errors=[],
                warnings=[],
                critical_issues=[
                    ValidationError(
                        error_type=ErrorType.INVALID_SHEET_STRUCTURE,
                        severity=ErrorSeverity.CRITICAL,
                        message=f"Unexpected error: {str(e)}",
                    )
                ],
                summary={
                    "total_issues": 1,
                    "critical_count": 1,
                    "error_count": 0,
                    "warning_count": 0,
                },
            ),
            "summary": {"total_issues": 1, "parse_attempted": False},
            "error_report": [f"üö® CRITICAL ERROR: {str(e)}"],
        }


# ...existing code...
def validate_spreadsheet_format(path: str) -> ValidationReport:
    """
    Perform comprehensive pre-import validation of the spreadsheet.

    Args:
        path: Path to the Excel file

    Returns:
        ValidationReport: Complete validation report with errors and warnings
    """
    errors = []
    warnings = []
    critical_issues = []

    try:
        # Check if file exists and is readable
        try:
            df = pd.read_excel(path, sheet_name=PRIMARY_SHEET)
        except FileNotFoundError:
            critical_issues.append(
                ValidationError(
                    error_type=ErrorType.INVALID_SHEET_STRUCTURE,
                    severity=ErrorSeverity.CRITICAL,
                    message=f"File not found: {path}",
                )
            )
            return _create_validation_report(critical_issues, errors, warnings, df=None)
        except Exception as e:
            critical_issues.append(
                ValidationError(
                    error_type=ErrorType.INVALID_SHEET_STRUCTURE,
                    severity=ErrorSeverity.CRITICAL,
                    message=f"Cannot read Primary Details sheet: {str(e)}",
                )
            )
            return _create_validation_report(critical_issues, errors, warnings, df=None)

        # Check required columns
        required_columns = ["item", "quantity", "Description"]
        missing_columns = [col for col in required_columns if col not in df.columns]
        if missing_columns:
            critical_issues.append(
                ValidationError(
                    error_type=ErrorType.MISSING_REQUIRED_COLUMNS,
                    severity=ErrorSeverity.CRITICAL,
                    message=f"Missing required columns: {', '.join(missing_columns)}",
                    suggestion="Ensure spreadsheet has 'item', 'quantity', and 'Description' columns",
                )
            )

        # Check for labour or material columns
        labour_col = detect_labour_column(df)
        material_total_col, material_item_col = detect_material_columns(df)

        if not labour_col and not material_total_col and not material_item_col:
            critical_issues.append(
                ValidationError(
                    error_type=ErrorType.MISSING_REQUIRED_COLUMNS,
                    severity=ErrorSeverity.CRITICAL,
                    message="No labour or material cost columns found",
                    suggestion="Ensure spreadsheet has either labour columns or material cost columns",
                )
            )

        # Validate individual items and detect conflicts
        labour_material_conflicts = _detect_labour_material_conflicts(
            df, labour_col, material_total_col, material_item_col
        )
        errors.extend(labour_material_conflicts)

        # Validate pricing against company defaults
        pricing_warnings = _validate_pricing_consistency(path, df)
        warnings.extend(pricing_warnings)

        # Check totals validation
        totals_warnings = _validate_totals_consistency(df, labour_col)
        warnings.extend(totals_warnings)

    except Exception as e:
        critical_issues.append(
            ValidationError(
                error_type=ErrorType.INVALID_SHEET_STRUCTURE,
                severity=ErrorSeverity.CRITICAL,
                message=f"Unexpected error during validation: {str(e)}",
            )
        )

    return _create_validation_report(critical_issues, errors, warnings, df)


def _detect_labour_material_conflicts(
    df, labour_col, material_total_col, material_item_col
) -> List[ValidationError]:
    """Detect items that have both labour and material costs."""
    conflicts = []

    if not labour_col or (not material_total_col and not material_item_col):
        return conflicts  # No conflict possible if missing columns

    for idx in range(min(45, len(df))):
        row = df.iloc[idx]
        excel_row = idx + 1

        # Check if this is a valid item
        if not _is_valid_item(row):
            continue
        # Check for conflict
        has_labour = _d(row.get(labour_col, 0)) > 0
        has_material = (
            _d(row.get(material_total_col, 0)) > 0
            or _d(row.get(material_item_col, 0)) > 0
        )

        if has_labour and has_material:
            description = str(row.get("Description", "")).strip()
            conflicts.append(
                ValidationError(
                    error_type=ErrorType.LABOUR_MATERIAL_CONFLICT,
                    severity=ErrorSeverity.ERROR,  # Blocking error - incorrect spreadsheet format
                    message=f"Item '{description}' has both labour and material costs",
                    row_number=excel_row,
                    suggestion="Remove either labour time or material costs - each item should be either labour OR material, not both",
                )
            )

    return conflicts


def _validate_pricing_consistency(path: str, df) -> List[ValidationError]:
    """Validate pricing against company defaults and pricing details sheet."""
    warnings = []

    try:
        # Get company defaults
        try:
            from apps.workflow.models import CompanyDefaults

            defaults = CompanyDefaults.objects.first()
            if defaults:
                defaults.wage_rate
                expected_charge = defaults.charge_out_rate
                expected_markup = defaults.materials_markup
            else:
                expected_charge = DEFAULT_CHARGE_OUT_RATE
                expected_markup = DEFAULT_MATERIALS_MARKUP
        except (ImportError, Exception):
            expected_charge = DEFAULT_CHARGE_OUT_RATE
            expected_markup = DEFAULT_MATERIALS_MARKUP

        # Check pricing details sheet
        try:
            pricing_df = pd.read_excel(path, sheet_name="pricing details - inhouse")

            # Find labour cost and margin
            labour_cost_row = None
            margin_row = None

            for idx, row in pricing_df.iterrows():
                desc = str(row.get("Description", "")).strip().lower()
                if "labour cost" in desc:
                    labour_cost_row = row
                elif "margin" in desc:
                    margin_row = row

            # Validate labour cost
            if labour_cost_row is not None:
                actual_labour_cost = _d(labour_cost_row.get("amount", 0))
                if abs(actual_labour_cost - expected_charge) > Decimal("1.00"):
                    warnings.append(
                        ValidationError(
                            error_type=ErrorType.CHARGE_RATE_MISMATCH,
                            severity=ErrorSeverity.WARNING,
                            message=f"Labour cost in pricing details (${actual_labour_cost}) doesn't match company charge-out rate (${expected_charge})",
                            expected_value=float(expected_charge),
                            actual_value=float(actual_labour_cost),
                            suggestion="Update company defaults or spreadsheet pricing",
                        )
                    )

            # Validate margin
            if margin_row is not None:
                actual_margin = _d(margin_row.get("amount", 0))
                expected_margin_multiplier = 1 + expected_markup
                if abs(actual_margin - expected_margin_multiplier) > Decimal("0.05"):
                    warnings.append(
                        ValidationError(
                            error_type=ErrorType.MARKUP_MISMATCH,
                            severity=ErrorSeverity.WARNING,
                            message=f"Margin in pricing details ({actual_margin}) doesn't match company markup ({expected_margin_multiplier})",
                            expected_value=float(expected_margin_multiplier),
                            actual_value=float(actual_margin),
                            suggestion="Update company defaults or spreadsheet pricing",
                        )
                    )

        except Exception:
            # Pricing details sheet not found or readable - this is optional
            pass

    except Exception as e:
        warnings.append(
            ValidationError(
                error_type=ErrorType.PRICING_MISMATCH,
                severity=ErrorSeverity.WARNING,
                message=f"Could not validate pricing consistency: {str(e)}",
            )
        )

    return warnings


def _validate_totals_consistency(df, labour_col) -> List[ValidationError]:
    """Validate that computed totals match spreadsheet totals."""
    warnings = []

    try:
        validation_cells = find_validation_cells(df, labour_col)

        # This is a simplified validation - full validation happens during parsing
        if not validation_cells.get("total_minutes"):
            warnings.append(
                ValidationError(
                    error_type=ErrorType.TOTALS_MISMATCH,
                    severity=ErrorSeverity.WARNING,
                    message="Could not find total minutes cell for validation",
                    suggestion="Check spreadsheet format and ensure totals are present",
                )
            )

        if not validation_cells.get("labour_revenue"):
            warnings.append(
                ValidationError(
                    error_type=ErrorType.TOTALS_MISMATCH,
                    severity=ErrorSeverity.WARNING,
                    message="Could not find labour revenue cell for validation",
                    suggestion="Check spreadsheet format and ensure labour totals are present",
                )
            )

    except Exception as e:
        warnings.append(
            ValidationError(
                error_type=ErrorType.TOTALS_MISMATCH,
                severity=ErrorSeverity.WARNING,
                message=f"Could not validate totals: {str(e)}",
            )
        )

    return warnings


def _is_valid_item(row) -> bool:
    """Check if a row represents a valid item."""
    # Item number is optional - we'll auto-assign if missing or invalid
    # No need to validate item number format since we'll handle that automatically

    # Must have quantity
    quantity = row.get("quantity")
    if pd.isna(quantity) or quantity is None or quantity == 0:
        return False

    # Description is optional - if empty, we'll use item number as fallback
    return True


def _create_validation_report(
    critical_issues: List[ValidationError],
    errors: List[ValidationError],
    warnings: List[ValidationError],
    df,
) -> ValidationReport:
    """Create a validation report from collected issues."""
    is_valid = len(critical_issues) == 0 and len(errors) == 0
    can_proceed = len(critical_issues) == 0 and len(errors) == 0

    # Create summary
    summary = {
        "total_issues": len(critical_issues) + len(errors) + len(warnings),
        "critical_count": len(critical_issues),
        "error_count": len(errors),
        "warning_count": len(warnings),
        "sheet_readable": df is not None,
        "estimated_items": (
            0
            if df is None
            else sum(
                1 for idx in range(min(45, len(df))) if _is_valid_item(df.iloc[idx])
            )
        ),
    }

    return ValidationReport(
        is_valid=is_valid,
        can_proceed=can_proceed,
        errors=errors,
        warnings=warnings,
        critical_issues=critical_issues,
        summary=summary,
    )
